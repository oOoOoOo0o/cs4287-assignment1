{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "Bayan Nezamabad - 20251971, Euan Bourke - 21332142\n",
    "\n",
    "The code executes to the end without errors\n",
    "\n",
    "While we did not reuse any existing implementations, a list of articles/documentation that was used to gain a better understanding of AlexNet and libraries we used is provided at the end of this notebook "
   ]
  },
  {
   "cell_type": "code",
   "id": "b6a06f02",
   "metadata": {},
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import utils, Sequential, layers\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from keras import backend"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "05de5d8d",
   "metadata": {},
   "source": [
    "# Hyper Params\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "OPTIMIZER = 'adam' # Default learning rate is 0.001\n",
    "\n",
    "VERBOSE = 1\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "METRICS = [\"accuracy\", \"precision\", \"recall\"]\n",
    "\n",
    "IMG_ROW, IMG_COL = 227, 227 # Image dimensions\n",
    "INPUT_SHAPE = (IMG_ROW, IMG_COL, 3) # 3 as RGB\n",
    "NB_CLASSES = 100 # 100 different classifications for 100 different species of butterfly or moth\n",
    "\n",
    "TRAIN_PATH = \"data/train\"\n",
    "VALID_PATH = \"data/valid\"\n",
    "TEST_PATH = \"data/test\"\n",
    "SEED = 123 # used for consistent randomisation of the dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The Data Set\n",
    "We chose a dataset consisting of images of butterflies and moths of 100 unique species (hence 100 unique classes).\n",
    "The dataset provided images for training, validation, and testing which is why we are loading a set of validation images instead of splitting the training set into training data and validation data (later in cross fold validation we do split the training dataset into training data and validation data).\n",
    "\n",
    "From the dataset there are many potential features one could identify but it's hard to tell what features our model will extract so to visualise the dataset, we will present a random sample image for 9 random classes. Some potential features that may contribute to successful classification are wing patterns, colours, wing shapes, body shapes, etc.\n",
    "We will also visualise the number of images per class in the form of a bar chart so that we may refer to it when evaluating our results, perhaps in case of any underfitting or overfitting. There isn't a huge amount of variance between the classes with an average training set size of 125 images but there are still a few outliers.\n",
    "\n",
    "Since we are using AlexNet, some preprocessing is performed upon loading our data. AlexNet requires that inputs have a shape of 227x227x3 but the images in our dataset are of size 224x224x3 so we resize the images in the code cell below."
   ],
   "id": "1c2b89447858c2ba"
  },
  {
   "cell_type": "code",
   "id": "2a862c54",
   "metadata": {},
   "source": [
    "# Loading and preparing training, validation, and testing data\n",
    "# Images are originally 224x224 so we have to resize them to 227x227, the input size of AlexNet\n",
    "train_data = utils.image_dataset_from_directory(TRAIN_PATH,\n",
    "                                                shuffle=True,\n",
    "                                                seed=SEED,\n",
    "                                                image_size=(IMG_COL, IMG_ROW), # Images are resized to 227 x 227\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                label_mode=\"categorical\")\n",
    "\n",
    "valid_data = utils.image_dataset_from_directory(VALID_PATH,\n",
    "                                                shuffle=True,\n",
    "                                                seed=SEED,\n",
    "                                                image_size=(IMG_COL, IMG_ROW), # Images are resized to 227 x 227\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                label_mode=\"categorical\")\n",
    "    \n",
    "test_data = utils.image_dataset_from_directory(TEST_PATH,\n",
    "                                               shuffle=True,\n",
    "                                               seed=SEED,\n",
    "                                               image_size=(IMG_COL, IMG_ROW), # Images are resized to 227 x 227\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               label_mode=\"categorical\")\n",
    "# Extracting test images and labels from the dataset\n",
    "X_test = [] # Array of images\n",
    "y_test = [] # Array of labels corresponding to the images\n",
    "for x_t, y_t in test_data:\n",
    "    for i in range(x_t.shape[0]):\n",
    "        X_test.append(x_t[i].numpy())\n",
    "        y_test.append(y_t[i].numpy())\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data Visualisation\n",
    "# We will first display some sample images from our dataset\n",
    "train_iterator = train_data.as_numpy_iterator()\n",
    "# Create a 3x3 grid to hold our images for compactness\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through 9 classes and take an image and class number from the training set\n",
    "for class_num in range(0, NB_CLASSES, 9):\n",
    "    batch = train_iterator.next()\n",
    "    image, label = batch[0][0], batch[1][0]\n",
    "    class_index = np.argmax(label)\n",
    "    # Store them in an array so we can later add them to our grid\n",
    "    images.append(image.astype(np.uint8))\n",
    "    labels.append(class_index)\n",
    "    \n",
    "for i in range(9):\n",
    "    # Get the row and column position to determine which ax to get\n",
    "    row_pos = i // 3\n",
    "    col_pos = i % 3\n",
    "    ax = axes[row_pos, col_pos]\n",
    "    # Display the image and class number\n",
    "    ax.imshow(images[i])\n",
    "    ax.set_title(f\"Class {labels[i]}\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# Get names of all classes from the training directory\n",
    "class_names = os.listdir(TRAIN_PATH)\n",
    "class_amounts = []\n",
    "\n",
    "# Get number of images for each class in the training directory\n",
    "for name in class_names:\n",
    "    class_dir = os.path.join(TRAIN_PATH, name)\n",
    "    class_amounts.append(len(os.listdir(class_dir)))\n",
    "\n",
    "# Alternate colours\n",
    "colours = ['#71b8d9', '#4686a3'] * (len(class_names) // 2)\n",
    "\n",
    "plt.figure(figsize=(25, 8))\n",
    "plt.bar(class_names, class_amounts, color=colours)\n",
    "plt.title(\"Number of Images per Class\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.show()"
   ],
   "id": "5d029a296d35e5ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A last preprocessing step we perform is to normalise our data using min-max normalisation.\n",
    "This is done by making the pixel values range 0 - 1 instead of the typical 0 - 255.\n",
    "\n",
    "This should help in making the training more 'fair' by making features contribute more equally and avoid certain features contributing too much. Learning from more features should increase the performance of our model."
   ],
   "id": "d21aa1b25d66441a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Min-max normalisation scales all values to the range 0 - 1\n",
    "# Division by 255 accomplishes this since the max value for any pixel in any colour channel is 255\n",
    "train_data = train_data.map(lambda x, y: (x / 255.0, y))\n",
    "valid_data = valid_data.map(lambda x, y: (x / 255.0, y))\n",
    "X_test /= 255.0"
   ],
   "id": "51c2e2216e1e4f09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Network Structure and Hyperparameters\n",
    "We chose to use the AlexNet architecture for our CNN.\n",
    "The architecture is described by the comments in the code cell below but we'll provide a brief summary:\n",
    "- Input Size: 227x227x3\n",
    "- 5 Convolutional layers with varying kernel numbers, kernel sizes and strides, all use the ReLU activation function.\n",
    "- 3 Max Pooling layers that simplify our inputs while trying to retain the features so that the training process is faster while retaining performance.\n",
    "- 3 Fully Connected layers with 2 Dropout layers and preceded by a Flatten layer. These layers take extracted features and bring them closer to a format that allows for classification. The dropout tries to lower the chance of overfitting (explained in the code cell).\n",
    "- An output layer using softmax to determine which label is most likely to be correct.\n",
    "\n",
    "Other hyperparameters are explained below:\n",
    "- Batch size is typically 128 for AlexNet\n",
    "- We settled on 30 epochs to balance training time and model performance. The validation metrics don't improve much beyond 30 epochs, if time wasn't a consideration, 50 epochs could be used but this isn't significantly better from what we can tell.\n",
    "- Learning rate is 0.001, the default used in the Adam optimiser, higher learning rates tended to provide worse results."
   ],
   "id": "696e073c562c2ada"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loss Function and Optimiser",
   "id": "55ca152b67147ebd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Implementation of AlexNet architecture\n",
    "class AlexNet(Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.build_layers()\n",
    "        # Compiles the model with our chosen optimiser, loss function, and metrics\n",
    "        self.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "    def build_layers(self):\n",
    "        # The architecture consists of 5 convolutional layers, 3 max pooling layers, 1 flatten layer, 3 fully connected layers (dropout following the first two), and an output layer\n",
    "        \n",
    "        # First convolutional layer consists of 96 filters, kernel size of 11x11, and moves in strides of 4\n",
    "        # This results in an output shape 55x55x96\n",
    "        self.add(layers.Conv2D(96, (11, 11), strides=(4, 4), activation=\"relu\", input_shape=INPUT_SHAPE))\n",
    "        self.add(layers.BatchNormalization())\n",
    "        # In max pooling we take the max value of a 3x3 region and move in strides of 2\n",
    "        # Resultant shape: 27x27x96\n",
    "        self.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "        # The resultant shape should be 27x27x256 so we apply even padding\n",
    "        self.add(layers.Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "        self.add(layers.BatchNormalization())\n",
    "        # Resultant shape: 13x13x256\n",
    "        self.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "        # Three more convolutional layers, only dimension changing here is z\n",
    "        self.add(layers.Conv2D(384, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        self.add(layers.BatchNormalization())\n",
    "        self.add(layers.Conv2D(384, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        self.add(layers.BatchNormalization())\n",
    "        self.add(layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        self.add(layers.BatchNormalization())\n",
    "\n",
    "        # Last max pooling layer results in 6x6x256\n",
    "        self.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "        # Flatten layer results in 1x1x9216 (6*6*256 = 9216)\n",
    "        self.add(layers.Flatten())\n",
    "\n",
    "        # Fully connected layers with dropout to prevent overfitting\n",
    "        self.add(layers.Dense(4096, activation=\"relu\"))\n",
    "        # 50% chance for each neuron to be deactivated\n",
    "        # Reduces overfitting by preventing over reliance on a specific feature and instead learning a more robust set of features\n",
    "        self.add(layers.Dropout(rate=0.5))\n",
    "        \n",
    "        self.add(layers.Dense(4096, activation=\"relu\"))\n",
    "        self.add(layers.Dropout(rate=0.5))\n",
    "        \n",
    "        self.add(layers.Dense(1000, activation=\"relu\"))\n",
    "        \n",
    "        # Softmax converts the input into probabilities for each class, emphasising the difference between input values\n",
    "        self.add(layers.Dense(NB_CLASSES, activation=\"softmax\"))\n",
    "\n",
    "model = AlexNet()\n",
    "model.summary()"
   ],
   "id": "84b4ee000a5bec9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training our model\n",
    "\n",
    "training_start_time = time.time()\n",
    "# Training\n",
    "model_history = model.fit(train_data, epochs=EPOCHS, validation_data=valid_data, verbose=VERBOSE)\n",
    "training_end_time = time.time()\n",
    "total_training_time = training_end_time - training_start_time\n",
    "\n",
    "# Displaying the total training time in minutes and seconds\n",
    "print(f\"Total training time: {total_training_time/60:.0f}m{total_training_time%60:.0f}s\")"
   ],
   "id": "deabf136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Obtaining metrics and calculating performance of our model to be used in visualising and evaluating results later\n",
    "\n",
    "# Obtaining metrics from training\n",
    "training_accuracy = model_history.history[\"accuracy\"]\n",
    "training_precision = model_history.history[\"precision\"]\n",
    "training_recall = model_history.history[\"recall\"]\n",
    "training_loss = model_history.history[\"loss\"]\n",
    "\n",
    "# Obtaining metrics from validation\n",
    "validation_accuracy = model_history.history[\"val_accuracy\"]\n",
    "validation_precision = model_history.history[\"val_precision\"]\n",
    "validation_recall = model_history.history[\"val_recall\"]\n",
    "validation_loss = model_history.history[\"val_loss\"]\n",
    "\n",
    "# Evaluating model against test data\n",
    "model_results = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "\n",
    "# Getting predicted results\n",
    "y_pred = model.predict(X_test)"
   ],
   "id": "e26638512e24d579",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cross Fold Validation\n",
    "Cross Fold validation was done separately so that we could try both using the validation dataset provided and by using the training dataset for validation to see if there was any noticeable difference in the results.\n",
    "\n",
    "We are using the same model, optimiser, loss function, hyperparameters, so that the results we get from cross fold validation can be compared with the results from the other approach.\n",
    "\n",
    "We chose to split the dataset into 3 equal-sized parts, 2 of which are being used for training and the other for validation. This also differs from the previous model we trained in that there is less training data and significantly more validation data.\n",
    "\n",
    "The process by which we did this is explained in the comments in the below code cell. The results are also provided in the output of the code cell. We average the results of the three models to gauge if combining these three models would yield better results than the single model approach."
   ],
   "id": "7ad7167e6e8d48f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training models with Cross Fold Validation\n",
    "\n",
    "# Splits is the number of folds\n",
    "splits = 3\n",
    "# Total number of elements in the training data\n",
    "dataset_size = len(list(train_data))\n",
    "# The number of elements in each fold\n",
    "fold_size = dataset_size // splits\n",
    "# The results of each fold will be stored in this array\n",
    "models_results = []\n",
    "\n",
    "# For each fold we will split the training data into 3 parts, 2 for training and 1 for validation and repeat for each possible permutation\n",
    "for fold in range(splits):\n",
    "    # We clear session so trained models don't interfere with each other\n",
    "    backend.clear_session()\n",
    "    # Create a new model\n",
    "    model = AlexNet()\n",
    "    # Train the model with the specific training sets and validation set\n",
    "    # Get the 'fold'th' third of the training data for validation (either the 1st, 2nd, or 3rd third)\n",
    "    valid_fold = train_data.skip(fold * fold_size).take(fold_size)\n",
    "    # Get the remaining training data for training (gets the data after the validation split and concatenates the data before the validation split)\n",
    "    train_fold = train_data.skip((fold+1) * fold_size).concatenate(train_data.take(fold * fold_size))\n",
    "    \n",
    "    model.fit(train_fold, epochs=EPOCHS, validation_data=valid_fold, verbose=VERBOSE)\n",
    "    # Evaluate the model and store the results\n",
    "    models_results.append(model.evaluate(X_test, y_test))"
   ],
   "id": "3102e0a2c280e245",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "### Single Model Results"
   ],
   "id": "3d4f5b8f5ab2dae3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Single model results\n",
    "# Visualising training results over time\n",
    "\n",
    "# Plotting model accuracy\n",
    "plt.plot(training_accuracy)\n",
    "plt.plot(validation_accuracy)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# Plotting model loss\n",
    "plt.plot(training_loss)\n",
    "plt.plot(validation_loss)\n",
    "plt.title(\"Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "# Plotting model precision\n",
    "plt.plot(training_precision)\n",
    "plt.plot(validation_precision)\n",
    "plt.title(\"Precision\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend([\"Train\", \"Val\"], loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plotting model recall\n",
    "plt.plot(training_recall)\n",
    "plt.plot(validation_recall)\n",
    "plt.title(\"Recall\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend([\"Train\", \"Val\"], loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "7070e35c4ed228a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Printing test results\n",
    "print(\"Test loss: \", round(model_results[0], 4))\n",
    "print(\"Test accuracy: \", round(model_results[1]*100, 1), \"%\")\n",
    "print(\"Test Precision: \", round(model_results[2]*100, 1), \"%\")\n",
    "print(\"Test Recall: \", round(model_results[3]*100, 1), \"%\")\n",
    "\n",
    "# Visualising test results\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Computing confusion matrix\n",
    "cm = metrics.confusion_matrix(y_true_classes, y_pred_classes)\n",
    "classes = [str(i) for i in range(NB_CLASSES)]\n",
    "cm_display = metrics.ConfusionMatrixDisplay(cm)\n",
    "\n",
    "# The matrix is 100x100 so the following lines make it a bit more visually accessible\n",
    "fig, ax = plt.subplots(figsize=(20, 20), dpi=200)\n",
    "plt.rcParams.update({\"font.size\": 8})\n",
    "\n",
    "# Plotting confusion matrix\n",
    "cm_display.plot(ax=ax, cmap=\"YlOrRd\", xticks_rotation=\"vertical\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.show()"
   ],
   "id": "be0fdcf9a95dfa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cross fold validation results",
   "id": "fc6f63a8bdc087e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cross fold validation results\n",
    "\n",
    "# Print the loss, accuracy, precision, and recall for each model\n",
    "for index, results in enumerate(models_results):\n",
    "    print(\"\\nModel\", index, \"loss:\", round(models_results[index][0], 4))\n",
    "    print(\"Model\", index, \"accuracy:\", round(models_results[index][1]*100, 1), \"%\")\n",
    "    print(\"Model\", index, \"precision:\", round(models_results[index][2]*100, 1), \"%\")\n",
    "    print(\"Model\", index, \"recall:\", round(models_results[index][3]*100, 1), \"%\")\n",
    "\n",
    "# Calculate the averages of each metric\n",
    "models_results = np.sum(models_results, axis=0)\n",
    "avg_loss = round((models_results[0] / 3), 4)\n",
    "avg_accuracy = round((models_results[1] / 3), 4)\n",
    "avg_precision = round((models_results[2] / 3), 4)\n",
    "avg_recall = round((models_results[3] / 3), 4)\n",
    "\n",
    "# Print the average metrics\n",
    "print(\"\\nAverage loss:\", avg_loss)\n",
    "print(\"Average accuracy:\", avg_accuracy*100, \"%\")\n",
    "print(\"Average Precision:\", avg_precision*100, \"%\")\n",
    "print(\"Average Recall:\", avg_recall*100, \"%\")"
   ],
   "id": "2c10a590e6fee46c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b20ee83b",
   "metadata": {},
   "source": [
    "Refs:\n",
    "\n",
    "AlexNet Architecture:\n",
    "\n",
    "https://www.kaggle.com/code/blurredmachine/alexnet-architecture-a-complete-guide\n",
    "\n",
    "https://medium.com/@siddheshb008/alexnet-architecture-explained-b6240c528bd5\n",
    "\n",
    "Keras docs:\n",
    "\n",
    "https://keras.io/api\n",
    "\n",
    "Matplotlib docs:\n",
    "\n",
    "https://matplotlib.org/stable/index.html\n",
    "\n",
    "Scikit-learn docs:\n",
    "\n",
    "https://scikit-learn.org/stable/api/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
